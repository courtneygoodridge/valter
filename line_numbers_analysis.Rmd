---
title: "Lie/numbers analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Decsciption and aim of this markdown

The aim of this markdown is replicate Valter's analysis of SNARC data using the R programming language. R provides a flexible way to analyse and visualise data. The markdown format allows for the analyse code to be separted into specific sections, and saved in html format. Before I continue into the analysis, I will remind both myself and Valter of the experiment:

## Experiment description - the context

Participants are told that they are hackers that have stolen codes. The police want to crack the code but participants have to communicate codes to their lawyers without being caught.

## Control_SNARC 

Participants shown just picture of the lawyer and a number. Participants have to respond with equivalent number (odd or even). This is the standard SNARC with context of being in a court.

## Lie_SNARC

In the lie condition, sometimes the picture is the lawyer and other times it is the cop. When it is the cop, they have to lie (i.e. repond with the opposite key, if the number is odd they had to respond as if it is  even). When the picture is a lawyer, they have to tell the truth (i.e. respond with the correct key). Here 2/3 trials are lawyer (standard SNARC) whereas the 1/3 of trials participants had to lie (does this have any effect on the SNARC?)

## What is being investigated?

SNARC effect - Spatial-Numerical Association of Codes effect proposes faster reaction times to small/large numbers on the left/right hand side.

MARC effect - Markedness of Response Codes effect proposes faster reaciton times for left/right hand side repsonses to odd/even numbers

Odd effect - faster reaction times to even numbers, slower reaction times for odd numbers. 

## Understanding column names and data types from the raw data

Key: a = left key, g = right key 

Accuracy: 1 = correct, 0 = incorrect

## Loading packages

```{r echo = TRUE,  message = 'hide', warning = 'hide', results = 'hide'}
# rm(list = ls())
# data visualisation
library(ggplot2) # for plotting
library(scales) # Scale Functions for Visualization
library(gplots) # for plotting

# data manipulation
library(dplyr) # data manipulation
library(tidyr) # data manipulation
library(readxl) # reading excel files 
library(openxlsx) # loads data sets from multiple sheets

# frequentist statistics
library(ez) # allows me to perform the ANOVA
library(car) # inferential stats
library(MASS) # inferential stats
library(EnvStats) # inferential stats
library(Rmisc) # confidence intervals 
library(sjstats) # for calculating effect sizes for ANOVA
library(effsize) # cohen's D function

# frequetist modelling/multi-level modelling
library(lme4) # for linear mixed effects modelling
library(nlme) # non linear mixed effects modelling
library(fitdistrplus) # fitting distribution modelling 
library(lmtest) # testing linear regression models
library(caret) # classification and regression training
library(merTools) # multi leveling modelling

# bayesian modelling and comparison
library(rstanarm) # for bayesian modelling
library(bayesplot) # for bayesian modelling
library(loo) # comparison of bayesian modelling
```

Above I am loading the packages that will be necessary for the analysis. Each package has specific utilities that will be needed to perform analysis. It is important to load them at the start of your script otherwise you will encounter errors.

## Loading data

```{r echo = TRUE, message = 'hide', warning = 'hide', results = 'hide'} 
# rm(list = ls()) clears environment
# dput(head(df,n)) provides example of data structure for stack overflow

# load control data
# set working directory on personal laptop
setwd("C:/Users/Courtney/Documents/PhD/Project/Experiment_code/valter")
# setwd("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/valter/")

dat <- loadWorkbook("Data_Lie_Numbers_Clean.xlsx")
sheetNames <- sheets(dat)
for(i in 1:length(sheetNames)){
  assign(sheetNames[i], readWorkbook(dat, sheet = i))
}
```

Here I am loading the data. I set my working directory using the *setwd()* function, and then load in data from both sheets of the excel file.

## Renaming conditions

```{r}
# cleaning control condition
controldata <- Control_SNARC %>%
  dplyr::select(numbers, condition, key, accuracy, RTs, participant) %>%
  arrange(participant) %>%
  mutate(condition = "controltrue")

# cleaning experimental conditon
Lie_SNARC <- Lie_SNARC %>%
  dplyr::select(numbers, condition, key, accuracy, RTs, participant) %>%
  arrange(participant)

exptrue <- Lie_SNARC %>%
  dplyr::filter(condition == "t") %>%
  mutate(condition = "exptrue")

explie <- Lie_SNARC %>%
  dplyr::filter(condition == "l") %>%
  mutate(condition = "explie")

workingdata <- rbind(controldata, exptrue, explie)

```

**Control**

The piece of code above is mainly for my own benefit - I am just renaming conditions. From the *Control_SNARC* dataframe, I am selecting the important columns (numbers, condition, accuracy, RTs and participant), I then arrange them by participant, and then rename name the condition "controltrue". This indicates it was a control condition and subjects had to tell the truth. I name this new dataframe "controldata".

*Experimental*

I select the relevant columns in the Lie_SNARC condition and arrange by participant. I then create two dataframes: one containing trials where the subject was telling the truth (I rename this exptrue) and one containing trials where the subject was telling a lie (I rename this explie).

*Overview*

With these new condition names, I combine the three dataframes into one overall dataframe called workingdata. I will be using this for the analysis and visualisation.

## Creating handedness column

```{r}
# creating handedness variable
left <- workingdata %>%
  dplyr::filter(key == "a") %>%
  mutate(hand = "left")

right <- workingdata %>%
  dplyr::filter(key == "g") %>%
  mutate(hand = "right")

workingdata <- rbind(left, right)
```

Again, this is for my own benefit. I am creating a column to replace "key". The new column is called hand and denotes the left or right hand to make it easier to understand the dataframe. I filter each key type into it's own dataframe, create a new "hand" variable and then recombine the dataframe.

## Creating parity column

```{r}
# creating parity variable
even <- workingdata %>%
  dplyr::filter(numbers %% 2 == 0) %>%
  mutate(parity = "even")

odd <- workingdata %>%
  dplyr::filter(numbers %% 2 == 1) %>%
  mutate(parity = "odd")

workingdata <- rbind(even, odd)

rm(controldata, explie, exptrue, left, right, even, odd)
```

Fianlly, I filter the data into odd and even number dataframes. I then create a a parity column indicating whether the number is odd or even. I recombine the dataframe and remove the other dataframes from the global environment using the *rm()* function. We are now ready to visualise some data. 

## Overview so far

I have cleaned the data and set it up in a way I feel comfortable. The data manipulation so is really personal preference, but I will be using the variables/variables names for the rest of the analysis.

## Overview conditions - error per condition and mean RTs (replication of slide 2)

The following code computes average errors and meanRTs for each condition.

```{r}
workingdata$condition <- factor(workingdata$condition, levels = c("controltrue", "exptrue", "explie"))

# errors percentage 
ggplot(workingdata %>%
  dplyr::group_by(condition, accuracy) %>%
  dplyr::summarise(acc_num = n()) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(condition) %>%
  dplyr::mutate(perc = (acc_num / sum(acc_num)) * 100) %>%
  dplyr::filter(accuracy == 0), aes(x = condition, y = perc)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(perc, 2),  vjust = -1)) +
  ylim(0, 15) +
  ylab("Percentage of errors (%)") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
  ggtitle("Errors %") +
  theme_gray() 

# errors in each condition
ggplot(dplyr::filter(workingdata, accuracy == 0) %>%
         dplyr::group_by(condition) %>%
         dplyr::summarise(errors = n()), aes(x = condition, y = errors)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = errors, vjust = -1)) +
  ylim(0, 900) +
  ylab("Numbers of errors") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
    ggtitle("Errors") +
  theme_gray() 

# mean RTS in each condition for correct repsonses
ggplot(dplyr::filter(workingdata, accuracy == 1) %>%
         dplyr::group_by(condition) %>%
         dplyr::summarise(meanRT = mean(RTs)), aes(x = condition, y = meanRT)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(meanRT, 2), vjust = -1)) +
  ylim(0, 1.2) +
  ylab("Mean reaction times (s)") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
  ggtitle("Mean RT") +
  theme_gray() 
```

The above code computes the graphs for slide 2 in the presentation that you sent to me (and that I sent back to you). The graphs visualise:

- Number of errors per condition (more errors in the condition where the police officer was present)
- Percentage of errors per condition (higher percentageof errors where the police officer was present)
- Mean reaction time per conditon (fasted RTs for the control condition i.e. no pictures, just standard SNARC)

I have tried to recreate the original graphs as closely as possible in order for you to see that it is possible to make these graphs in R. I have titled them as you have in the presentation to make it easier to which graph relates to which. 

The following code chunks analyse the lawyer only data i.e. the control condition when subjects just had to tell the truth.

## Control condition RTs (lawyer only) - Odd effect and MARC effect for RTs (replication of slide 3)

```{r}
### line graph - RTs over different numbers
ggplot(data = workingdata %>%
         dplyr::filter(condition == "controltrue") %>%
         dplyr::group_by(numbers, hand) %>%
         dplyr::summarise(meanRT = mean(RTs)), aes(x = numbers, y = meanRT, col = hand)) +
  geom_point() +
  geom_line() +
  scale_x_continuous("Numbers", breaks = seq(0, 9, 1)) +
  scale_y_continuous("Mean RT (s)", breaks = seq(0, 0.62, 0.02)) +
  ggtitle("RTs for left and right hands across numbers")

lawyeronly <- workingdata %>%
  dplyr::filter(condition == "controltrue")

### Odd effect - plots with 95% CIs and corresponding t-test
lawyeronly$parity <- factor(lawyeronly$parity, levels = c("odd", "even"))

ggplot(data = summarySE(lawyeronly, measurevar = "RTs", groupvars = c("parity")), aes(x = parity, y = RTs)) + 
  geom_col() +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .2) +
  coord_cartesian(ylim = c(0.55, 0.60)) +
  ggtitle("Odd effect RT analysis")

lawyerttest <- lawyeronly %>%
  dplyr::select(RTs, parity, participant)

lawyerttest <- reshape(lawyerttest, idvar = "participant", timevar = "parity", direction = "wide")

t.test(lawyerttest$RTs.even, lawyerttest$RTs.odd, paired = TRUE)
cohen.d(lawyerttest$RTs.even, lawyerttest$RTs.odd, paired = TRUE)

### MARC effect - plots 95% CIs and corresponding 2x2 ANOVA
lawyeronly$parity <- factor(lawyeronly$parity, levels = c("odd", "even"))
lawyeronly$hand <- factor(lawyeronly$hand, levels = c("left", "right"))

ggplot(data = summarySE(lawyeronly, measurevar = "RTs", groupvars = c("parity", "hand")), aes(x = parity, color = hand, group = hand, y = RTs)) +
         stat_summary(fun.y = mean, geom = "point") +
         stat_summary(fun.y = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ggtitle("MARC effect RT analysis")

result_MARC <- ezANOVA(lawyeronly, dv = RTs, wid = participant, within = .(parity, hand), type = 3, detailed = TRUE, return_aov = TRUE)
result_MARC

eta_sq(result_MARC$aov, partial = TRUE)
```

This code chunk aims to replicate slide 3 of the summary analysis.

**Left-Right line graph**

Line graph represents the mean reaction times for each hand responded with (left and right) for various numbers in the control condition. As we might expect, reaction times are faster for congruent hand-parrity pairs (left-odd, right-even).

**Odd effect plot and t-test**

The 95% CIs match the example. Mean RTs are slightly different - unsure why when the number of participants is the same... either way, the pattern of results is the same.

I then perform a t-test to compare the 2 means (I'm unsure why in the example an f value is computed instead of  t value). Either way, it comes out as non-signifcant [t(37) = 1.81, p = 0.07].

**MARC effect plot and 2X2 ANOVA**

Appears to the show a fairly strong parity x hand interaction - RTs are faster when the hand repsonded with and the pairty are conrguent (left-odd, right-even).

2x2 ANOVA reveals significant interaction with large effect size.

## Control condition RTs (lawyer only) - SNARC effect for RTs (replication of slide 4)

```{r}
### creating magnitude variable
small <- lawyeronly %>%
  dplyr::filter(numbers <= 4) %>%
  dplyr::mutate(magnitude = "small")

large <- lawyeronly %>%
  dplyr::filter(numbers > 4) %>%
  dplyr::mutate(magnitude = "large")

lawyeronly <- rbind(small, large)

### SNARC effect - plot with 95% CIs and 2x2 ANOVA
lawyeronly$magnitude <- factor(lawyeronly$magnitude, levels = c("small", "large"))
lawyeronly$hand <- factor(lawyeronly$hand, levels = c("left", "right"))

ggplot(data = summarySE(lawyeronly, measurevar = "RTs", groupvars = c("magnitude", "hand")), aes(x = magnitude, color = hand, group = hand, y = RTs)) +
         stat_summary(fun.y = mean, geom = "point") +
         stat_summary(fun.y = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ggtitle("SNARC effect RT analysis")

result_SNARC <- ezANOVA(lawyeronly, dv = RTs, wid = participant, within = .(magnitude, hand), type = 3, detailed = TRUE, return_aov = TRUE)
result_SNARC

eta_sq(result_SNARC$aov, partial = TRUE)

### regression plot

lawyeronly$numbers <- as.numeric(lawyeronly$numbers)

ggplot(data = lawyeronly %>%
         dplyr::group_by(numbers) %>%
         dplyr::summarise(m = mean(RTs)), aes(x = numbers, y = m)) +
  geom_point() +
  geom_smooth(method = "lm") +
  scale_x_continuous(breaks = seq(1, 9, 1), limits = c(1, 9)) +
  ggtitle("Linear model of number magnitude and RTs") +
  xlab("Numbers (magnitude)") +
  ylab("mean reaction time (s)")
```

Firstly I make dataframes *small* and *large* in order to compute a new variable called magnitude. This will be used (alongside hand) to analyse the SNARC effect

**2x2 factorial ANOVA**

Significant main effect of magnitude (smaller number reacted to faster) however more importantly, a significant interatcion with large effect size. This indicates a classic SNARC in the only lawyer control condition (i.e. when responding to larger numbers with right hard, RTs are faster. When responding to small numbers with left hand, RTs are faster). 

**Regression (linear model)**

I was a litte bit confused about the regression here. On slide 4, it appears you plot the number magnitudes against differences in reaction times for the SNARC effect? I have plotted the number magnitudes against average reaction times which is slightly different. Happy to have another go once I understand what the regression in slide 4 is trying to show.

##  Control condition errors (lawyer only) - Odd effect error analysis (replication of slide 5)

**Why I do slightly different analysis to what was sent**

For investigating errors in the contorl lawyer condition, I utilise a generalised linear mixed effects model - specificaly, a logistic mixed effect GLM.Accuracy is a dichotomous dependent variable and thus the assumptions of a standard ANOVA will be violated. Hence a logistic GLM can be used to model an event that exists in a pass/fail, correct/error state, such as accuracy in this case.

For these models, I specify binomial as the distribution family because I am modelling a response with 2 outcomes - correct and wrong.

I use mixed effect in order to account for the repeated measures design. I specify that each participant has their own intercept (a random effect) to model for each subject.

I also focus on the accuracy percentage rather than the number of errors - this helps with the interpretation of the logistic regression models as they assess the probability of a correct answer. Higher probability of correct answer relates to increased accuracy percentage

```{r}
### Odd effect error analysis with logistic regression
ggplot(summarySE(lawyeronly, measurevar = "accuracy", groupvars = c("parity")), aes(x = parity, y = accuracy)) + 
  geom_col() +
  geom_errorbar(aes(ymin = accuracy - ci, ymax = accuracy + ci), width = .2) +
  coord_cartesian(ylim = c(0.80, 1)) +
  ylab("Accuracy (%)") +
  scale_x_discrete("Parity", labels = c("odd" = "Odd", "even" = "Even")) +
  ggtitle("Odd effect - error analysis")

oddeffect_model <- glmer(accuracy ~ parity + (1 | participant),
             data = lawyeronly,
             family = binomial(link = "logit"))

summary(oddeffect_model)

exp(0.5125)

(1 - exp(0.5125)) * 100
```

The effect of parity here refers to responding to even numbers and their accuracy when doing so. The logistic GLM indicates a significant effect of parity via the object *parityeven*. The estimate output is positive, suggesting that the even numbers significantly increase the probability of an accurate response. Plotting errors in a bar chart visualises this - even numbers have lower number of errors made. 

To further investiagte this, we must look at the estimate. If we exponentiate the logistic regression estimate, we can interepret it as an odds ratio i.e. the association between exposure (even or odd numbers) and the outcome (a correct or incorrect response). Doing this indicates that the odds of a correct response increase by a factor of 1.66946 (66%) when numbers are even i.e. the correct answer is 1.6 times more likely when the number is even versus when it is odd. This statistically highlights the odd effect. 

##  Control condition errors (lawyer only) - MARC effect error analysis (replication of slide 5)

```{r}
### MARC effect for errors/accuracy
lawyeronly$hand = factor(lawyeronly$hand, levels = c("left", "right"))
lawyeronly$parity = factor(lawyeronly$parity, levels = c("odd", "even"))

ggplot(data = summarySE(lawyeronly, measurevar = "accuracy", groupvars = c("parity", "hand")), aes(x = parity, color = hand, group = hand, y = accuracy)) +
         stat_summary(fun.y = mean, geom = "point") +
         stat_summary(fun.y = mean, geom = "line") +
  geom_errorbar(aes(ymin = accuracy - ci, ymax = accuracy + ci), width = .1) +
  ylab("Response accuracy (%)") +
  xlab("Parity") +
  ggtitle("MARC effect - error analysis")

MARCeffect_model <- glmer(accuracy ~ hand * parity + (1 | participant),
             data = lawyeronly,
             family = binomial(link = "logit"))

summary(MARCeffect_model)

exp(-0.7641)
```

**Error analysis of the MARC effect**

Because we have a significant interaction, this is what our focus should be on. As mentioned for the odd effect, the exponentiated coefficient of the main effect gives your the odds ratio. However, the exponentiated coefficient of the interaction refers to theratio by which the odds ratio changes. 

In the context of the MARC effect, we find a significant interaction between hand and parity via the *handright:parityeven* object. Once exponentiated, this indicates that when responding to an even number, the odds ratio for people responding with their right hand decreases by a factor of 0.4657529. Intuitively this seems to be the opposite of the traditional MARC effect as we would expect responding to even numbers to increase the odds ratio of an accurate response when responding with the right hand. It appears their is an inversed MARC effect. 

Implementing a line plot visualises this interaction. Accuracy is reduced for left + odd pairs and right + even pairs. This is the opposite of the traditional MARC effect. 

##  Control condition errors (lawyer only) - SNARC effect error analysis (replication of slide 5)

```{r}
# SNARC effect for errors/accuracy
lawyeronly$hand = factor(lawyeronly$hand, levels = c("right", "left"))
lawyeronly$magnitude = factor(lawyeronly$magnitude, levels = c("small", "large"))

ggplot(data = summarySE(lawyeronly, measurevar = "accuracy", groupvars = c("magnitude", "hand")), aes(x = magnitude, color = hand, group = hand, y = accuracy)) +
         stat_summary(fun.y = mean, geom = "point") +
         stat_summary(fun.y = mean, geom = "line") +
  geom_errorbar(aes(ymin = accuracy - ci, ymax = accuracy + ci), width = .1) +
  ylab("Response accuracy (%)") +
  xlab("Magnitude") +
  ggtitle("SNARC effect - error analysis")

SNARCeffect_model <- glmer(accuracy ~ hand * magnitude + (1 | participant),
             data = lawyeronly,
             family = binomial(link = "logit"))

summary(SNARCeffect_model)
```

The *handleft:magnitudelarge* pairing estimate suggests that when compared against another pairing, the probability of an accurate response increases. Intuitively this seems to be the opposite of the traditional SNARC effect (lower accuracy when magnitude and hand are incongruant). Thus I implement a line plot to visualise the significant interaction.

The line plot visualises this interaction. Accuracy is reduced for left + small pairs and right + large pairs. This is the opposite of the traditional SNARC effect.

**Overview**

RTs also show evidence of SNARC and MARC effect via significant ANOVAs

Logistic regression analysis for the error effects matche the analysis on slide 5 - there is a significant odd effect (increased probability of errors with an odd number) however the MARC and SNARC effects are inverted. Despite matching results, I believe I have used a more appropriate analyse technique given the nature of the data (dichotomous variables).

Now that the lawyer only condition is analysed (both accuracy and RTs), the focus switches to experimental condition. We start with the when the lawyer is present in the "lie" experimental condition

## Lawyer lie RTs (lawyer in experimental condition) - Odd effect and MARC effect for RTs (replication of slide 7)

```{r}
### line graph - RTs over different numbers
ggplot(data = workingdata %>%
         dplyr::filter(condition == "exptrue") %>%
         dplyr::group_by(numbers, hand) %>%
         dplyr::summarise(meanRT = mean(RTs)), aes(x = numbers, y = meanRT, col = hand)) +
  geom_point() +
  geom_line() +
  scale_x_continuous("Numbers", breaks = seq(0, 9, 1)) +
  scale_y_continuous("Mean RT (s)", breaks = seq(0, 0.82, 0.02)) +
  ggtitle("RTs for left and right hands across numbers")


lawyerlie <- workingdata %>%
  dplyr::filter(condition == "exptrue")

### Odd effect - plots with 95% CIs and corresponding t-test
lawyerlie$parity <- factor(lawyerlie$parity, levels = c("odd", "even"))

ggplot(data = summarySE(lawyerlie, measurevar = "RTs", groupvars = c("parity")), aes(x = parity, y = RTs)) + 
  geom_col() +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .2) +
  coord_cartesian(ylim = c(0.62, 0.82)) +
  ggtitle("Odd effect RT analysis")

lawyerliettest <- lawyerlie %>%
  dplyr::select(RTs, parity, participant)

lawyerliettest <- reshape(lawyerliettest, idvar = "participant", timevar = "parity", direction = "wide")

t.test(lawyerliettest$RTs.even, lawyerliettest$RTs.odd, paired = TRUE)
cohen.d(lawyerliettest$RTs.even, lawyerliettest$RTs.odd, paired = TRUE)

### MARC effect - plots 95% CIs and corresponding 2x2 ANOVA
lawyerlie$parity <- factor(lawyerlie$parity, levels = c("odd", "even"))
lawyerlie$hand <- factor(lawyerlie$hand, levels = c("left", "right"))

ggplot(data = summarySE(lawyerlie, measurevar = "RTs", groupvars = c("parity", "hand")), aes(x = parity, color = hand, group = hand, y = RTs)) +
         stat_summary(fun.y = mean, geom = "point") +
         stat_summary(fun.y = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ggtitle("MARC effect RT analysis")

result_MARC <- ezANOVA(lawyerlie, dv = RTs, wid = participant, within = .(parity, hand), type = 3, detailed = TRUE, return_aov = TRUE)
result_MARC

eta_sq(result_MARC$aov, partial = TRUE)
```

**Left-right line graph**

As per the lawyer control condition, we see faster RTs when parity and hand responded with are conrguent.

**Odd effect**
 
T-test reveales significant odd effect - faster reaction times for even numbers.
 
**MARC effect**

ANOVA aslo reveals significant interaction between parity and hand responded with alongside a large effect size indicating a MARC effect. 