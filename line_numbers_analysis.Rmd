---
title: "Lie/numbers analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Decsciption and aim of this markdown

The aim of this markdown is replicate Valter's analysis of SNARC data using the R programming language. R provides a flexible way to analyse and visualise data. The markdown format allows for the analyse code to be separted into specific sections, and saved in html formt. Before I continue into the analysis, I will remind both myself and Valter of the experiment:

**Experiment description - the context**

Participants are told that they are hackers that have stolen codes. The police want to crack the code but participants have to communicate codes to their lawyers without being caught.

**Control_SNARC** 

Participants shown just picture of the lawyers and a number. Participants have to respond with equivalent number (odd or even). This is the standard SNARC with context of being in a court.

**Lie_SNARC**

In the lie condition, sometimes the picture is the lawyer and other times it is the cop. When it is the cop, they have to lie (i.e. repond with the opposite key, if the number is odd they had to respond as if it is  even). When the picture is a lawyer, they have to tell the truth (i.e. respond with the correct key). Here 2/3 trials are true (standard SNARC) whereas the 1/3 of trials participants had to lie (does this have any affect on the SNARC?

**Understanding column names and data types from the raw data**

Key: a = left key, g = right key 

Accuracy: 1 = correct, 0 = incorrect

## Loading packages

```{r}
# data visualisation
library(ggplot2) # for plotting
library(scales) # Scale Functions for Visualization
library(gplots) # for plotting

# data manipulation
library(dplyr) # data manipulation
library(tidyr) # data manipulation
library(readxl) # reading excel files 
library(openxlsx) # loads data sets from multiple sheets

# frequentist statistics
library(ez) # allows me to perform the ANOVA
library(car) # inferential stats
library(MASS) # inferential stats
library(EnvStats) # inferential stats
library(Rmisc) # confidence intervals 
library(sjstats) # for calculating effect sizes

# frequetist modelling/multi-level modelling
library(lme4) # for linear mixed effects modelling
library(nlme) # non linear mixed effects modelling
library(fitdistrplus) # fitting distribution modelling 
library(lmtest) # testing linear regression models
library(caret) # classification and regression training
library(merTools) # multi leveling modelling

# bayesian modelling and comparison
library(rstanarm) # for bayesian modelling
library(bayesplot) # for bayesian modelling
library(loo) # comparison of bayesian modelling

```

Above I am loading the packages that will be necessary for the analysis. Each package has specific utilities that will be needed to perform analysis. It is important to load them at the start of your script otherwise you will encounter errors.

## Loading data

```{r} 
# rm(list = ls())

# load control data
# set working directory on personal laptop
setwd("C:/Users/Courtney/Documents/PhD/Valter")
# setwd("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/valter/")

dat <- loadWorkbook("Data_Lie_Numbers_Clean.xlsx")
sheetNames <- sheets(dat)
for(i in 1:length(sheetNames)){
  assign(sheetNames[i], readWorkbook(dat, sheet = i))
}

```

Here I am loading the data. I set my working directory using the *setwd()* function, and then load in data from both sheets of the excel file.

## Renaming conditions

```{r}
# cleaning control condition
controldata <- Control_SNARC %>%
  dplyr::select(numbers, condition, key, accuracy, RTs, participant) %>%
  arrange(participant) %>%
  mutate(condition = "controltrue")

# cleaning experimental conditon
Lie_SNARC <- Lie_SNARC %>%
  dplyr::select(numbers, condition, key, accuracy, RTs, participant) %>%
  arrange(participant)

exptrue <- Lie_SNARC %>%
  dplyr::filter(condition == "t") %>%
  mutate(condition = "exptrue")

explie <- Lie_SNARC %>%
  dplyr::filter(condition == "l") %>%
  mutate(condition = "explie")

workingdata <- rbind(controldata, exptrue, explie)

```

*Control*

The piece of code above is mainly for my own benefit - I am just renaming conditions. From the *Control_SNARC* dataframe, I am selecting the important columns (numbers, condition, accuracy, RTs and participant), I then arrange them by participant, and then rename name the condition "controltrue". This indicates it was a control condition and subjects had to tell the truth. I name this new dataframe "controldata".

*Experimental*

I select the relevant columns in the Lie_SNARC condition and arrange by participant. I then create two dataframes: one containing trials where the subject was telling the truth (I rename this exptrue) and one containing trials where the subject was telling a lie (I rename this explie).

*Overview*

With these new condition names, I combine the three dataframes into one overall dataframe called workingdata. I will be using this for the analysis and visualisation.

## Creating handedness column

```{r}
# creating handedness variable
left <- workingdata %>%
  dplyr::filter(key == "a") %>%
  mutate(hand = "left")

right <- workingdata %>%
  dplyr::filter(key == "g") %>%
  mutate(hand = "right")

workingdata <- rbind(left, right)
```

Again, this is for my own benefit. I am creating a column to replace "key". The new column is called hand and denotes the left or right hand to make it easier to understand the dataframe. I filter each key type into it's own dataframe, create a new "hand" variable and then recombine the dataframe.

## Creating parity column

```{r}
# creating parity variable
even <- workingdata %>%
  dplyr::filter(numbers %% 2 == 0) %>%
  mutate(parity = "even")

odd <- workingdata %>%
  dplyr::filter(numbers %% 2 == 1) %>%
  mutate(parity = "odd")

workingdata <- rbind(even, odd)

rm(controldata, expdata, explie, exptrue, left, right, even, odd)
```

Fianlly, I filter the data into odd and even number dataframes. I then create a a parity column indicating whether the number is odd or even. I recombine the dataframe and remove the other dataframes from the global environment using the *rm()* function. We are now ready to visualise some data. 

## Overview so far

I have cleaned the data and set it up in a way I feel comfortable. The data manipulation so is really personal preference, but I will be using the variables/variables names for the rest of the analysis.

## Overview conditions - error per condition and mean RTs

```{r}
# errors percentage 

ggplot(workingdata %>%
  dplyr::group_by(condition, accuracy) %>%
  dplyr::summarise(acc_num = n()) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(condition) %>%
  dplyr::mutate(perc = (acc_num / sum(acc_num)) * 100) %>%
  dplyr::filter(accuracy == 0), aes(x = condition, y = perc)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(perc, 2),  vjust = -1)) +
  ylim(0, 15) +
  ylab("Percentage of errors (%)") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
  ggtitle("Percentage of errors per condition") +
  theme_gray() 

# errors in each condition

ggplot(dplyr::filter(workingdata, accuracy == 0) %>%
         dplyr::group_by(condition) %>%
         dplyr::summarise(errors = n()), aes(x = condition, y = errors)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = errors, vjust = -1)) +
  ylim(0, 900) +
  ylab("Numbers of errors") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
  ggtitle("Number of errors per condition") +
  theme_gray() 

# mean RTS in each condition for correct repsonses

ggplot(dplyr::filter(workingdata, accuracy == 1) %>%
         dplyr::group_by(condition) %>%
         dplyr::summarise(meanRT = mean(RTs)), aes(x = condition, y = meanRT)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(meanRT, 2), vjust = -1)) +
  ylim(0, 1.2) +
  ylab("Mean reaction times (s)") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
  ggtitle("Mean reaction time per condition") +
  theme_gray() 
```


```{r ONLY LAYWER - control condition (RT)}

# line graph demonstrating RTs over each number subjects were given
ggplot(data = workingdata %>%
         dplyr::filter(condition == "controltrue") %>%
         dplyr::group_by(numbers, hand) %>%
         summarise(meanRT = mean(RTs)), aes(x = numbers, y = meanRT, col = hand)) +
  geom_point() +
  geom_line()

# bar charts (with 95% confidence intervals) shwoing RTs for odd and even numbers
OddEffect <- workingdata %>%
  dplyr::filter(condition == "controltrue")

CI_OddEffect <- summarySE(OddEffect, measurevar = "RTs", groupvars = c("parity"))

ggplot(CI_OddEffect, aes(x = parity, y = RTs)) + 
  geom_line() +
  geom_errorbar(aes(ymin = RTs - se, ymax = RTs + se), width = .1) +
  geom_point()

t.test(RTs ~ parity, data = OddEffect)

# MARC effect bar chart (with 95% confidence intervals) for parity x hand - shows interaction

result <- ezANOVA(workingdata, dv = RTs, wid = participant, within = .(parity, hand), type = 3, detailed = TRUE, return_aov = TRUE)
result

eta_sq(result$aov, partial = TRUE)

CIerror_bar <- summarySE(workingdata, measurevar = "RTs", groupvars = c("parity", "hand"))

ggplot(data = CIerror_bar, aes(x = parity, color = hand, group = hand, y = RTs)) +
         stat_summary(fun.y = mean, geom = "point") +
         stat_summary(fun.y = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - se, ymax = RTs + se), width = .1)

```

*Notes on this section of the analysis*

*Line plots on left and right hand versus number responding to*
Line plots match the ones displayed by Valter

*Odd effect*
Unsure why Valter has done an ANOVA for testing the parity because there are only 2 factors (odd and even). Either way, it comes out as non-signifcant. I also prefer the mean points with error bars rather than with bar charts.

*2x2 ANOVA (parity x hand)*
My data set seems to have more participants than Valter's which might explain why my results are significant and his are not. I also prefer the line graphs to see the interaction.

*TO DO*

- Check if I'm importing data right - I can import data from one excel files from multiple sheets? (Yes I can, I just need to figure out how).

