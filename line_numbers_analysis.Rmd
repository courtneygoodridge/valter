---
title: "Lie/numbers analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Decsciption and aim of this markdown

The aim of this markdown is to replicate Valter's analysis of SNARC data using the R programming language. R provides a flexible way to analyse and visualise data. The markdown format allows for the analysis code to be separted into specific sections, and saved into a html format. Before I continue into the analysis, I will remind both myself and Valter of the experiment:

## Experiment description - the context

Participants are told that they are hackers that have stolen codes. The police want to crack the code but participants have to communicate codes to their lawyers without being caught.

## Control_SNARC 

Participants shown just picture of the lawyer and a number. Participants have to respond with equivalent number (odd or even). This is the standard SNARC with context of being in a court.

## Lie_SNARC

In the lie condition, sometimes the picture is the lawyer and other times it is the cop. When it is the cop, they have to lie (i.e. repond with the opposite key, if the number is odd they had to respond as if it is  even). When the picture is a lawyer, they have to tell the truth (i.e. respond with the correct key). Here 2/3 trials are lawyer (standard SNARC) whereas the 1/3 of trials participants had to lie (does this have any effect on the SNARC?)

## What is being investigated?

SNARC effect - Spatial-Numerical Association of Codes effect proposes faster reaction times to small/large numbers on the left/right hand side.

MARC effect - Markedness of Response Codes effect proposes faster reaciton times for left/right hand side repsonses to odd/even numbers

Odd effect - faster reaction times to even numbers, slower reaction times for odd numbers. 

## Understanding column names and data types from the raw data

Key: a = left key, g = right key 

Accuracy: 1 = correct, 0 = incorrect

## A brief description of the packages I will be using

To manipulate dataframes for analysis and data visualisations, I will be using a package called *dplyr*. This package provides functions such as *dplyr::filter()* (to filter by specific values), *dplyr::group_by()* (to group by a specific variable before performing a calculation) and others. This package also has something called a pipe (*%>%*). This symbol essential means "and then do this" which allows you to use varying functions to manipulate the dataframe before using it.

It works in concordance with other packages (*ggplot2*) so you can manipulate dataframes to visualise data, without having to create lots of new dataframes from scratch. 

## Loading packages

The first thing I do is load the necessary packages needed for the analysis. I have surpressed the output here to save space, however it is important to loads the packages at the start of your script otherwise you might encounter errors.

```{r echo = TRUE, include = FALSE}
# rm(list = ls())

"Data visualiation"
library(ggplot2) # for plotting

"Data manipulation/loading"
library(dplyr) # data manipulation
library(tidyr) # data manipulation
library(readxl) # reading excel files 
library(openxlsx) # loads data sets from multiple sheets
library(XLConnect)

"Inferential stats and modelling"
library(car) # inferential stats
library(MASS) # inferential stats
library(EnvStats) # inferential stats
library(Rmisc) # confidence intervals 
library(sjstats) # for calculating effect sizes for ANOVA
library(effsize) # cohen's D function
library(lme4) # for linear mixed effects modelling
library(lmtest) # testing linear regression models
library(fitdistrplus) # distribution fits
library(ez) # repeated measures ANOVA 
```

## Loading data

```{r echo = TRUE, message = 'hide', warning = 'hide', results = 'hide'} 
dat <- lapply(excel_sheets("C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/valter/Data_Lie_Numbers_Clean.xlsx"), read_excel, path = "C:/Users/pscmgo/OneDrive for Business/PhD/Project/Experiment_Code/valter/Data_Lie_Numbers_Clean.xlsx")


Control_SNARC <- as.data.frame(dat[1])

Lie_SNARC <- as.data.frame(dat[2])
```

Here I am loading the data. I set the path as my working directory load the data from both sheets of the excel file and then save them as seperate dataframes.

## Checking for na values

```{r, echo=TRUE}
Lie_SNARC %>%
  dplyr::select(numbers, accuracy, RTs) %>%
  dplyr::filter(is.na(RTs))

Control_SNARC %>%
  dplyr::select(numbers, accuracy, RTs) %>%
  dplyr::filter(is.na(RTs))
```

The first thing I do when I get a new dataset is check for na values. If these are not sorted, they can become an issue when analysing the data. I use the *is.na()* function to tell me where and how many na values each dataset has. In the *Lie_SNARC* dataset, I have 43 trials with an na value within the RT column. For the *Control_SNARC* dataset, I have 1 trial with an value within the RT column.

To further investigate, I filter both dataframes to look at the trials that have na values. For each na, the accurary is 0. I assume what has happened is the subject has ran out of time to respond or inputted an invalid resposne thus they do not get an RT and the accuracy is indicated as an error.

**Dealing with NA values**

When focusing on just error analysis, I shall keep the na values as they provide interesting information (i.e. conditions where subjects did no provide a response). For the MARC and SNARC analysis, I will have to remove the na values as there is no *response_hand* if no response is recorded.

## Renaming conditions

```{r, echo=TRUE}
Control_SNARC <- Control_SNARC %>%
  dplyr::select(numbers, condition, key, accuracy, RTs, participant) %>%
  arrange(participant) %>%
  mutate(condition = "controltrue")

Lie_SNARC <- Lie_SNARC %>%
  dplyr::select(numbers, condition, key, accuracy, RTs, participant) %>%
  arrange(participant) %>%
  dplyr::mutate(condition = case_when(condition == "t" ~ "exptrue",
                                      condition == "l" ~ "explie"))
workingdata <- rbind(Control_SNARC, Lie_SNARC)
```

The piece of code above is mainly for my own benefit - I am just renaming conditions. From the *Control_SNARC* dataframe, I am selecting the important columns (numbers, condition, accuracy, RTs and participant), I then arrange them by participant, and then rename name the condition *"controltrue"*. This indicates it was a control condition and subjects had to tell the truth i.e. the basic SNARC effect.

The *Lie_SNARC* dataframe contains trials from the experimental block - either where subjects still had to tell the truth, or if they had to lie. I found the *t* and *l* names confusing, so I rename them exptrue and explie.

I then combine both dataframes into one overall dataframe called *workingdata*.

## Creating handedness column

```{r, echo=TRUE}
workingdata <- workingdata %>%
  dplyr::mutate(response_hand = case_when(key == "a" ~ "left",
                                          key == "g" ~ "right"))
```

Again, this is for my own benefit. I am creating a column to replace "key" as I found it confusing. The new column is called hand and denotes the left or right hand to make it easier to understand the dataframe.

The *case_when* function allows me to create a new column of data dependiing on the value of another variable - in this case, *key*.

## Creating parity column

```{r, echo=TRUE}
workingdata <- workingdata %>%
  dplyr::mutate(parity = ifelse(numbers %% 2 == 0, "even", "odd"))
```

Finally, I create a *parity* column. The *ifelse()* function evaluates the first argument. When the value in the numbers column is divided by 2, if it equals 0 create a new column and insert *even*. For an other value after dividing, it much be odd thus insert *odd*.

I have cleaned the data and set it up in a way I feel comfortable. The data manipulation so far is personal preference, but I will be using the variables created above for the rest of the analysis.

## General overview of the conditions - (replication of slide 2)

The following code computes average errors and meanRTs for each condition.

```{r, echo=FALSE}
workingdata$condition <- factor(workingdata$condition, levels = c("controltrue", "exptrue", "explie"))

"error pecentage" 
ggplot(workingdata %>%
  dplyr::group_by(condition, accuracy) %>%
  dplyr::summarise(acc_num = n()) %>%
  dplyr::ungroup() %>%
  dplyr::group_by(condition) %>%
  dplyr::mutate(perc = (acc_num / sum(acc_num)) * 100) %>%
  dplyr::filter(accuracy == 0), aes(x = condition, y = perc)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(perc, 2),  vjust = -1)) +
  ylim(0, 15) +
  ylab("Percentage of errors (%)") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
  ggtitle("Errors %") +
  theme_gray() 

"errors per condition"
ggplot(workingdata %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::group_by(condition) %>%
         dplyr::summarise(errors = n()), aes(x = condition, y = errors)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = errors, vjust = -1)) +
  ylim(0, 1000) +
  ylab("Numbers of errors") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
    ggtitle("Errors") +
  theme_gray() 

"mean RTS per  condition"
ggplot(workingdata %>%
         drop_na() %>%
         dplyr::filter(accuracy == 1) %>%
         dplyr::group_by(condition) %>%
         dplyr::summarise(meanRT = mean(RTs)), aes(x = condition, y = meanRT)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(meanRT, 2), vjust = -1)) +
  ylim(0, 1.2) +
  ylab("Mean reaction times (s)") +
  scale_x_discrete("Condition", labels = c("controltrue" = "Control", "explie" = "Police", "exptrue" = "Lawyer")) +
  ggtitle("Mean RT") +
  theme_gray() 
```

Computing the graphs for slide 2 in the presentation that you sent to me (and that I sent back to you). The graphs visualise:

- Number of errors per condition (more errors in the condition where the police officer was present)
- Percentage of errors per condition (higher percentage of errors where the police officer was present)
- Mean reaction time per conditon (faster RTs for the control condition i.e. just standard SNARC)

## Control condition - lawyer only - MARC effect error analysis - replication of slide 3

```{r, echo=FALSE}
"RTs over different numbers"
ggplot(workingdata %>%
         drop_na() %>%
         dplyr::filter(condition == "controltrue") %>%
         dplyr::group_by(numbers, response_hand) %>%
         dplyr::summarise(meanRT = mean(RTs)), aes(x = numbers, y = meanRT, col = response_hand)) +
  geom_point() +
  geom_line() +
  scale_x_continuous("Numbers", breaks = seq(0, 9, 1)) +
  ylim(0, 0.65) +
  ylab("Mean RTs (s)") +
  ggtitle("RTs for left and right hands across numbers")

"Odd effect (95% CIs and corresponding t-test)"
workingdata$parity <- factor(workingdata$parity, levels = c("odd", "even"))

ggplot(workingdata %>%
         drop_na() %>%
         dplyr::filter(condition == "controltrue") %>%
         summarySE(measurevar = "RTs", groupvars = c("parity")), aes(x = parity, y = RTs)) + 
  geom_col() +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .2) +
  ylim(0, 0.65) +
  ggtitle("Odd effect RT analysis")

control_ttest_df <- workingdata %>%
  drop_na() %>%
  dplyr::filter(condition == "controltrue") %>%
  dplyr::select(RTs, parity, participant)

control_ttest_df <- reshape(control_ttest_df, idvar = "participant", timevar = "parity", direction = "wide")

t.test(control_ttest_df$RTs.even, control_ttest_df$RTs.odd, paired = TRUE)
cohen.d(control_ttest_df$RTs.even, control_ttest_df$RTs.odd, paired = TRUE)

"MARC effect RTs"
workingdata$parity <- factor(workingdata$parity, levels = c("odd", "even"))
workingdata$response_hand <- factor(workingdata$response_hand, levels = c("left", "right"))

ggplot(workingdata %>%
         drop_na() %>%
         dplyr::filter(condition == "controltrue") %>%
         summarySE(measurevar = "RTs", groupvars = c("parity", "response_hand")), aes(x = parity, color = response_hand, group = response_hand, y = RTs)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ylim(0, 0.65) +
  ggtitle("MARC effect RT analysis")


MARC <- glmer(RTs ~ parity * response_hand + (1 | participant),
              family = Gamma(link = "identity"),
              data = workingdata %>%
                drop_na() %>%
                dplyr::filter(condition == "controltrue"))

summary(MARC)
```

This code chunk aims to replicate slide 3 of the summary analysis.

**Left-Right line graph**

Line graph represents the mean reaction times for each hand responded with (left and right) for various numbers in the control condition. As we might expect, reaction times are faster for congruent hand-parity pairs (left-odd, right-even).

**Odd effect plot and t-test**

The 95% CIs match the example. Mean RTs are slightly different by looking at the degrees of freedom, the number of participants are not the same (perhaps I have a more updated dataset?). Either way, the pattern of results is the same.

The corresponding t-test comparing the 2 means comes out as non-signifcant [t(37) = 0.23, p = 0.81].

**MARC effect 2X2 ANOVA and my suggestion**

A standard ANOVA assumes a normal distribution, however RTs rarely follow a normal distribution. GLMs and GLMERs often provide more statistical power when analysing RT data because you can specify an error distribution that fits your data better (such as Gamma or Inverse-Gaussian for RT data). This paper details differences in analysing RT data between linear and generalised linear *mixed effects* model however I think the same applies when not specifying mixed effects (https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full). You also might want to think about implementing mixed effects in your analysis - you have a repeated measures design and subjects might be more variable in some of the experimental conditions, which a mixed effects model can account for.

**Fixed effects**

The results indicate a negative effect on RT when the parity and response hand are congruent [beta = -0.06, t = -6.05, p < 0.001]. This indicates the standard MARC effect.

**Random effects**

Standard deviations for participant intercepts are actually quite high with regard to the fixed effects estimate, suggesting some variability between participants. 

## Control condition -  lawyer only - SNARC effect for RTs (replication of slide 4)

```{r, echo=FALSE}
"creating magnitude variable"
workingdata <- workingdata %>%
  dplyr::mutate(magnitude = case_when(numbers <= 4 ~ "small",
                                      numbers > 4 ~ "large"))
"SNARC effect RTs"
workingdata$magnitude <- factor(workingdata$magnitude, levels = c("small", "large"))
workingdata$response_hand <- factor(workingdata$response_hand, levels = c("left", "right"))

ggplot(workingdata %>%
         drop_na() %>%
         dplyr::filter(condition == "controltrue") %>%
         summarySE(measurevar = "RTs", groupvars = c("magnitude", "response_hand")), aes(x = magnitude, color = response_hand, group = response_hand, y = RTs)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ylim(0, 0.65) +
  ggtitle("SNARC effect RT analysis")

SNARC <- glmer(RTs ~ magnitude * response_hand + (1 | participant),
              family = Gamma(link = "identity"),
              data = workingdata %>%
                drop_na() %>%
                dplyr::filter(condition == "controltrue"))

summary(SNARC)
```

Firstly I make dataframes *small* and *large* in order to compute a new variable called magnitude. This will be used (alongside hand) to analyse the SNARC effect

**Fixed effects**

The results indicate a negative effect on RT when the parity and response hand are congruent [beta = -0.02, t = -2.57, p = 0.009]. This indicates the standard SNARC effect.

**Random effects**

Standard deviations for participant intercepts are actually quite high with regard to the fixed effects estimate, suggesting some variability between participants. 

This indicates a classic SNARC in the only lawyer control condition (i.e. when responding to larger numbers with right hard, RTs are faster. When responding to small numbers with left hand, RTs are faster). 

## Control condition -  lawyer only - Odd effect error analysis - assessing distribution

For the odd effect error analyses, I do a slightly different analysis to what you did. For investigating errors in the control condition, I utilise a generalised linear mixed effects model - specifically, a logistic mixed effect regression. I do this for the following reasons:

1) Accuracy data is binomial. This means it is a dichotomous dependent variable that exists in one of two states - correct or incorrect. This violates the assumptions of a standard ANOVA, thus we can model the data better if we specify the correct error distribution. 

2) When you have a dichotomous dependent variable, it is desirable to have a model and that predicts whether a value is 0 or 1. A linear regression (essentially a standard ANOVA) does not allow you to do this because the predicted y variable may not be restricted to a value between 0 and 1. Conversely, a logistic model can produce the odds of the occurence of an event. 

3) The experimental design was repeated measures, which allows for the inclusion of participants as a random effect in a multi-level model. This means we can model an between participant variability in RT and thus capture more unexplained variance. Again, this will provide more statistical power. 

Below, I fit the 2 distributions to the data to demonstrate why a logistic regression is more appropriate than an ANOVA

```{r, echo=FALSE}
dist <- workingdata %>%
  dplyr::filter(condition == "controltrue")

fit_log  <- fitdist(dist$accuracy, "logis")
fit_norm <- fitdist(dist$accuracy, "norm")

"logistic"
fit_log$aic

"normal"
fit_norm$aic
```

To demonstrate this, I fit the accuracy data to both a logistic and normal distribution. As you can see via AIC value (lower number demonstrate better fits), the logistic distribution is a much better fit. Because of this, we should us a logistic regression rather than an ANOVA.

## Control condition -  lawyer only - Odd effect error analysis - replication of slide 5

To compute a logistic regression, I need to specify a binomial distribution. A binomial distribution is a discrete probability distribution. This means it focuses on the number of successes within a sample which is what we need when focusing on accuracy. I also include a *logit* link function which is a transformation parameter - it is the logarithm of odds. This means we can investigate how manipulating our independent variable affects the odds of scoring an accurate response. 

I use mixed effect in order to account for the repeated measures design. I specify that each participant has their own intercept (a random effect) to model for each subject.

```{r, echo=FALSE}
"Odd effect error analysis"
ggplot(workingdata %>%
         dplyr::filter(condition == "controltrue") %>%
         drop_na() %>%
         dplyr::group_by(parity) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()), aes(x = parity, y = errors)) + 
  geom_col() +
  ylab("Number of errors") +
  scale_x_discrete("Parity", labels = c("odd" = "Odd", "even" = "Even")) +
  ggtitle("Odd effect - error analysis")

oddeffect_model <- glmer(accuracy ~ parity + (1 | participant),
             data = workingdata %>%
               dplyr::filter(condition == "controltrue") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(oddeffect_model)

exp(fixef(oddeffect_model))
exp(confint(oddeffect_model))
```

**Coefficients versus odds ratio**
When performing logistic regressions, coefficients can be hard to interpret due to the dichotomous nature of the data. If we exponentiate the coefficient, we get the odds-ratio.

- If an odds ratio is 1, both outcomes have an equal chance of occurring. For example if the odd ratio was 1, accurate and error responses would be equally as likely when responding with the left and right hand. 

- If an odds ratio is below 1, then a particular level of parity would decrease the chance of an accurate result. For example, an odds ratio of 0.5 would mean a level of parity has odds of 1:2, or a accurate result for every two errors.

- If an odds-ratio is larger than 1, a level of parity would increase the chance of an accurate result. For example, an odds ratio of 3 would mean a level of parity has odds of 3:1 or 3 accurate results for every 1 error.

**Interpretation of our results**

**Fixed effects odds ratio**

The fixed effects coefficient for even numbers is 0.51 corresponds to the log of odds ratio between even and odd numbers. This coefficient is hard to interpret, thus we exponentiate it. This reveals an odds ratio of 1.66 which means the odds of an accurate response are 1.66:1, or 66% higher for even numbers than for odd numbers.

**Random effects**

The standard deviation of the random effects is quite high in relation to the the estimate. This suggests some substantial variability between partipants in reaction time. This also supports our rationale. 

##  Control condition - lawyer only - MARC effect error analysis - replication of slide 5

```{r, echo=FALSE}
"MARC effect error analysis"
workingdata$response_hand = factor(workingdata$response_hand, levels = c("left", "right"))
workingdata$parity = factor(workingdata$parity, levels = c("odd", "even"))

ggplot(workingdata %>%
         dplyr::filter(condition == "controltrue") %>%
         drop_na() %>%
         dplyr::group_by(parity, response_hand) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()) %>%
         dplyr::ungroup(), aes(x = parity, color = response_hand, group = response_hand, y = errors)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  ylim(0, 70) +
  ylab("Number of errors") +
  xlab("Parity") +
  ggtitle("MARC effect - error analysis")

MARCeffect_model <- glmer(accuracy ~ response_hand * parity + (1 | participant),
             data = workingdata %>%
               drop_na() %>%
               dplyr::filter(condition == "controltrue") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(MARCeffect_model)

exp(fixef(MARCeffect_model))
exp(confint(MARCeffect_model))
```

**Fixed effects**

The fixed effects coefficient for the interaction (*response_handright:parityeven*) is -0.76 which corresponds to the log of odds ratio between congruent and incongruent response hand/parity pairs.  We exponentiate it to reveal an odds ratio of 0.46 which means the odds of 
an accurate response are 0.46:1, or 54% lower when response hand and parity are congruent. Hence this highlights an inversed MARC effect.

The line plot visualises this interaction. However the plot also reveals something else - this interaction appears to be driven by responding with the left hand. The number of errors with the right hand is consistent whether repsonding to even or odd numbers. However the difference for the left hand is much bigger.

**Random effects**

Once again the standard deviation of the random intercepts shows variability between subjects (SD = 0.38).

##  Control condition - lawyer only - SNARC effect error analysis - replication of slide 5

```{r, echo=FALSE}
"SNARC effect errors"
workingdata$response_hand = factor(workingdata$response_hand, levels = c("left", "right"))
workingdata$magnitude = factor(workingdata$magnitude, levels = c("small", "large"))

ggplot(workingdata %>%
         dplyr::filter(condition == "controltrue") %>%
         drop_na() %>%
         dplyr::group_by(magnitude, response_hand) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()) %>%
         dplyr::ungroup(), aes(x = magnitude, color = response_hand, group = response_hand, y = errors)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  ylim(0, 60) +
  ylab("Number of errors") +
  xlab("Magnitude") +
  ggtitle("SNARC effect - error analysis")

SNARCeffect_model <- glmer(accuracy ~ response_hand * magnitude + (1 | participant),
             data = workingdata %>%
               drop_na() %>%
               dplyr::filter(condition == "controltrue") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(SNARCeffect_model)

exp(fixef(SNARCeffect_model))
exp(confint(SNARCeffect_model))
```

**Fixed effects**

The fixed effects coefficient for the interaction (*response_handright:magnitudelarge*) is -0.94 which corresponds to the log of odds ratio between congruent and incongruent response hand/magnitude pairs. We exponentiate it to reveal an odds ratio of 0.39 which means the odds of an accurate response are 0.39:1, or 61% lower when the response hand and parity are congruent. This highlights an inversed SNARC.

I implement a line plot to visualise the significant interaction. The line plot visualises this interaction. As highlighted by the logistic regression model, accuracy is higher for left + small pairs and right + large pairs. This is the opposite of the traditional SNARC effect.

**Random effects**

Once again the standard deviation of the random intercepts shows variability between subjects (SD = 0.38).

## Overview of the analysis and results of the control condition

RTs show evidence of SNARC and MARC effect via significant ANOVAs (however I would possibly suggests using GLMs to analyse this).

Logistic regression analysis for the error effects matches the analysis on slide 5 - there is a significant odd effect, however the MARC and SNARC effects are inverted. The results match, however I believe I have used a more appropriate analyse technique given the nature of the data.

Like Valter suggested, there could be trade off - decreases in reaction time lead to decreases in accuracy for the observed effects.

Now that the control condition is analysed (both accuracy and RTs), the focus switches to experimental condition. We start with the when the lawyer is present in the "lie" experimental condition

## Experimental condition - lawyer only - Odd and MARC effect for RTs - replication of slide 7

```{r,echo=FALSE}
"RTs over different numbers"
ggplot(data = workingdata %>%
         drop_na() %>%
         dplyr::filter(condition == "exptrue") %>%
         dplyr::group_by(numbers, response_hand) %>%
         dplyr::summarise(meanRT = mean(RTs)), aes(x = numbers, y = meanRT, col = response_hand)) +
  geom_point() +
  geom_line() +
  scale_x_continuous("Numbers", breaks = seq(0, 9, 1)) +
  ylim(0, 0.90) +
  ggtitle("RTs for left and right hands across numbers")

"Odd effect (95% CIs and corresponding t-test)"
workingdata$parity <- factor(workingdata$parity, levels = c("odd", "even"))

ggplot(workingdata %>%
         dplyr::filter(condition == "exptrue") %>%
         drop_na() %>%
         summarySE(measurevar = "RTs", groupvars = c("parity")), aes(x = parity, y = RTs)) + 
  geom_col() +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .2) +
  ylim(0, 0.90) +
  ggtitle("Odd effect RT analysis")

exp_true_ttest <- workingdata %>%
  dplyr::filter(condition == "exptrue") %>%
  dplyr::select(RTs, parity, participant)

exp_true_ttest <- reshape(exp_true_ttest, idvar = "participant", timevar = "parity", direction = "wide")

t.test(exp_true_ttest$RTs.even, exp_true_ttest$RTs.odd, paired = TRUE)
cohen.d(exp_true_ttest$RTs.even, exp_true_ttest$RTs.odd, paired = TRUE)

"MARC effect RTs"
workingdata$parity <- factor(workingdata$parity, levels = c("odd", "even"))
workingdata$response_hand <- factor(workingdata$response_hand, levels = c("left", "right"))

ggplot(workingdata %>%
         dplyr::filter(condition == "exptrue") %>%
         drop_na() %>%
         summarySE(measurevar = "RTs", groupvars = c("parity", "response_hand")), aes(x = parity, color = response_hand, group = response_hand, y = RTs)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ylim(0, 0.90) +
  ggtitle("MARC effect RT analysis")

MARC <- glmer(RTs ~ parity * response_hand + (1 | participant),
              family = Gamma(link = "identity"),
              data = workingdata %>%
                drop_na() %>%
                dplyr::filter(condition == "exptrue"))

summary(MARC)
```

**Left-right line graph**

As per the lawyer control condition, we see faster RTs when parity and response hand are conrguent.

**Odd effect**
 
T-test reveals significant odd effect - faster reaction times for even numbers [t(37 = -3.30), p = 0.002], however the effect size is small (-0.39).
 
**Fixed effects**

The results indicate a negative effect on RT when the parity and response hand are congruent [beta = -0.07, t = -8.50, p < 0.001]. This indicates the standard SNARC effect.

**Random effects**

Standard deviations for participant intercepts are actually quite high with regard to the fixed effects estimate, suggesting some variability between participants. 


## Experimental condition - lawyer only - SNARC effect for RTs - replication of slide 8

```{r, echo=FALSE}
"SNARC effect RTs"
workingdata$magnitude <- factor(workingdata$magnitude, levels = c("small", "large"))
workingdata$response_hand <- factor(workingdata$response_hand, levels = c("left", "right"))

ggplot(workingdata %>%
         drop_na() %>%
         dplyr::filter(condition == "exptrue") %>%
         summarySE(measurevar = "RTs", groupvars = c("magnitude", "response_hand")), aes(x = magnitude, color = response_hand, group = response_hand, y = RTs)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ylim(0, 0.85) +
  ggtitle("SNARC effect RT analysis")

SNARC <- glmer(RTs ~ magnitude * response_hand + (1 | participant),
              family = Gamma(link = "identity"),
              data = workingdata %>%
                drop_na() %>%
                dplyr::filter(condition == "exptrue"))

summary(SNARC)
```

**Fixed effects**

The results indicate a negative effect on RT when the parity and response hand are congruent [beta = -0.02, t = -3.10, p = 0.001]. This indicates the standard SNARC effect.

**Random effects**

Standard deviations for participant intercepts are actually quite high with regard to the fixed effects estimate, suggesting some variability between participants. 

## Experimental condition - lawyer only - Odd effect error analysis - replication of slide 9

```{r, echo=FALSE}
"Odd effect error analysis"
ggplot(workingdata %>%
         dplyr::filter(condition == "exptrue") %>%
         drop_na() %>%
         dplyr::group_by(parity) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()), aes(x = parity, y = errors)) + 
  geom_col() +
  ylab("Number of errors") +
  scale_x_discrete("Parity", labels = c("odd" = "Odd", "even" = "Even")) +
  ggtitle("Odd effect - error analysis")

oddeffect_model <- glmer(accuracy ~ parity + (1 | participant),
             data = workingdata %>%
               dplyr::filter(condition == "exptrue") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(oddeffect_model)

exp(fixef(oddeffect_model))
exp(confint(oddeffect_model))
```

**Fixed effects**

The fixed effects coefficient for even numbers is 0.27 which corresponds to the log of odds ratio between even and odd numbers. We exponentiate it revealing an odds ratio of 1.31 which means the odds of an accurate response are 1.31:1, or 31% higher for even numbers.

**Random effects**

The standard deviation of the random effects is quite high in relation to the the estimate (SD = 0.72). This suggests some substantial variability between partipants in accuracy.

## Experimental condition - lawyer only - MARC effect error analysis - replication of slide 9

```{r, echo=FALSE}
"MARC effect error analysis"
workingdata$response_hand = factor(workingdata$response_hand, levels = c("left", "right"))
workingdata$parity = factor(workingdata$parity, levels = c("odd", "even"))

ggplot(workingdata %>%
         dplyr::filter(condition == "exptrue") %>%
         drop_na() %>%
         dplyr::group_by(parity, response_hand) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()) %>%
         dplyr::ungroup(), aes(x = parity, color = response_hand, group = response_hand, y = errors)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  ylim(0, 200) +
  ylab("Number of errors") +
  xlab("Parity") +
  ggtitle("MARC effect - error analysis")

MARCeffect_model <- glmer(accuracy ~ response_hand * parity + (1 | participant),
             data = workingdata %>%
               drop_na() %>%
               dplyr::filter(condition == "exptrue") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(MARCeffect_model)

exp(fixef(MARCeffect_model))
exp(confint(MARCeffect_model))
```

**Fixed effects**

The fixed effects coefficient for the interaction (*response_handright:parityeven*) is -0.58 which corresponds to the log of odds ratio between congruent versus incongruent response hand/parity pairs.  We exponentiate it to reveal an odds ratio of 0.55 which means the odds of an accurate response are 0.55:1, or 45% lower when response hand and parity are congruent. Hence this highlights an inversed SNARC.

**Random effects**

Random effects highlight substantial variation in errors between participants for this condition (SD = 0.716).

## Experimental condition - lawyer only - SNARC effect error analysis - replication of slide 9

```{r, echo=FALSE}
"SNARC effect for errors"
workingdata$response_hand = factor(workingdata$response_hand, levels = c("left", "right"))
workingdata$magnitude = factor(workingdata$magnitude, levels = c("small", "large"))

ggplot(workingdata %>%
         dplyr::filter(condition == "exptrue") %>%
         drop_na() %>%
         dplyr::group_by(magnitude, response_hand) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()) %>%
         dplyr::ungroup(), aes(x = magnitude, color = response_hand, group = response_hand, y = errors)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  ylim(0, 180) +
  ylab("Number of errors") +
  xlab("Magnitude") +
  ggtitle("SNARC effect - error analysis")

SNARCeffect_model <- glmer(accuracy ~ response_hand * magnitude + (1 | participant),
             data = workingdata %>%
               drop_na() %>%
               dplyr::filter(condition == "exptrue") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(SNARCeffect_model)

exp(fixef(SNARCeffect_model))
exp(confint(SNARCeffect_model))
```

**Fixed effects**

The fixed effects coefficient for the interaction (*response_handright:magnitudelarge*) is -0.54 which corresponds to the log of odds ratio between congruent versus incongruent response hand/magnitude pairs.  We exponentiate it to reveal an odds ratio of 0.57 which means the odds of an accurate response are 0.57:1, or 43% lower when response hand and parity are congruent. Hence this highlights an inversed SNARC.

The line plot visualises this interaction. Accuracy is reduced for left + small pairs and right + large pairs. This is the opposite of the traditional SNARC effect.


**Random effects**

Again, substantial variation between subjects in the errors made (SD = 0.719)

## Overview of experimental condition (lawyer only)

The analysis provide the same results as the control condition. The results here mirror those in Valter original analysis, however I propose computing a logistic mixed effects models. Now move onto the final condition - experimental where the cop is also present. 

## Experimental condition - cop and lawyer present - Odd and MARC effect for RTs - replication of slide 11

```{r, echo=FALSE}
"RTs over different numbers"
ggplot(data = workingdata %>%
         drop_na() %>%
         dplyr::filter(condition == "explie") %>%
         dplyr::group_by(numbers, response_hand) %>%
         dplyr::summarise(meanRT = mean(RTs)), aes(x = numbers, y = meanRT, col = response_hand)) +
  geom_point() +
  geom_line() +
  ylim(0, 1) +
  scale_x_continuous("Numbers", breaks = seq(0, 9, 1)) +
  ggtitle("RTs for left and right hands across numbers")

"Odd effect (95% CIs and corresponding t-test)"
workingdata$parity <- factor(workingdata$parity, levels = c("odd", "even"))

ggplot(workingdata %>%
         dplyr::filter(condition == "explie") %>%
         drop_na() %>%
         summarySE(measurevar = "RTs", groupvars = c("parity")), aes(x = parity, y = RTs)) + 
  geom_col() +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .2) +
  ylim(0, 1) +
  ggtitle("Odd effect RT analysis")

exp_true_ttest <- workingdata %>%
  dplyr::filter(condition == "explie") %>%
  dplyr::select(RTs, parity, participant)

exp_true_ttest <- reshape(exp_true_ttest, idvar = "participant", timevar = "parity", direction = "wide")

t.test(exp_true_ttest$RTs.even, exp_true_ttest$RTs.odd, paired = TRUE)
cohen.d(exp_true_ttest$RTs.even, exp_true_ttest$RTs.odd, paired = TRUE)

"MARC effect RTs"
workingdata$parity <- factor(workingdata$parity, levels = c("odd", "even"))
workingdata$response_hand <- factor(workingdata$response_hand, levels = c("left", "right"))

ggplot(workingdata %>%
         dplyr::filter(condition == "explie") %>%
         drop_na() %>%
         summarySE(measurevar = "RTs", groupvars = c("parity", "response_hand")), aes(x = parity, color = response_hand, group = response_hand, y = RTs)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ylim(0, 1.10) +
  ggtitle("MARC effect RT analysis")

MARC <- glmer(RTs ~ parity * response_hand + (1 | participant),
              family = Gamma(link = "identity"),
              data = workingdata %>%
                drop_na() %>%
                dplyr::filter(condition == "explie"))

summary(MARC)
```

**Left-right line graph**

No obviously visible relationship between response hand and numbers. Perhaps the beginning of an inverse MARC effect (right hand responses appear quicker for a few odd numbers - 1, 3, 7, 9 however this could just be random variation). 

**Odd effect**
 
T-test reveals no significant odd effect.

**Fixed effects**

Model reveals no significant interaction

## Experimental condition - lawyer and cop present - SNARC effect for RTs - replication of slide 12

```{r, echo=FALSE}
"SNARC effect RTs"
workingdata$magnitude <- factor(workingdata$magnitude, levels = c("small", "large"))
workingdata$response_hand <- factor(workingdata$response_hand, levels = c("left", "right"))

ggplot(workingdata %>%
         drop_na() %>%
         dplyr::filter(condition == "explie") %>%
         summarySE(measurevar = "RTs", groupvars = c("magnitude", "response_hand")), aes(x = magnitude, color = response_hand, group = response_hand, y = RTs)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  geom_errorbar(aes(ymin = RTs - ci, ymax = RTs + ci), width = .1) +
  ylim(0, 1) +
  ggtitle("SNARC effect RT analysis")

SNARC <- glmer(RTs ~ magnitude * response_hand + (1 | participant),
              family = Gamma(link = "identity"),
              data = workingdata %>%
                drop_na() %>%
                dplyr::filter(condition == "explie"))

summary(SNARC)
```

**Fixed effects**

Main effects and interactions remain non-significant. Line plot indicates no real relationship that I can make sense of.

## Experimental condition - cop and lawyer present - Odd effect error analysis - replication of slide 13

```{r, echo=FALSE}
"Odd effect error analysis"
ggplot(workingdata %>%
         dplyr::filter(condition == "explie") %>%
         drop_na() %>%
         dplyr::group_by(parity) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()), aes(x = parity, y = errors)) + 
  geom_col() +
  ylab("Number of errors") +
  scale_x_discrete("Parity", labels = c("odd" = "Odd", "even" = "Even")) +
  ggtitle("Odd effect - error analysis")

oddeffect_model <- glmer(accuracy ~ parity + (1 | participant),
             data = workingdata %>%
               dplyr::filter(condition == "explie") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(oddeffect_model)

exp(fixef(oddeffect_model))
exp(confint(oddeffect_model))
```

**Fixed effects**

The fixed effects coefficient for even numbers is 0.10 corresponds to the log of odds ratio between even and odd numbers. Exponentiating reveals an odds ratio of 1.11 which means the odds of an accurate response are 1.1:1, or 11% higher for even numbers. This is not a particular big increase in the odds of an accurate response, which supports the non-significant result.

**Random effects**

The standard deviation of the random effects is once again quite high in relation to the the estimate (SD = 0.67) suggesting substantial variability between partipants in accuracy.

## Experimental condition - lawyer and cop present - MARC effect error analysis - replication of slide 13

```{r, echo=FALSE}
"MARC effect error analysis"
workingdata$response_hand = factor(workingdata$response_hand, levels = c("left", "right"))
workingdata$parity = factor(workingdata$parity, levels = c("odd", "even"))

ggplot(workingdata %>%
         dplyr::filter(condition == "explie") %>%
         drop_na() %>%
         dplyr::group_by(parity, response_hand) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()), aes(x = parity, color = response_hand, group = response_hand, y = errors)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  ylim(0, 250) +
  ylab("Number of errors") +
  xlab("Parity") +
  ggtitle("MARC effect - error analysis")

MARCeffect_model <- glmer(accuracy ~ response_hand * parity + (1 | participant),
             data = workingdata %>%
               drop_na() %>%
               dplyr::filter(condition == "explie") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(MARCeffect_model)

exp(fixef(MARCeffect_model))
exp(confint(MARCeffect_model))
```

**Fixed effects**

After exponentiating the log of odds estimate, the odds of an accurate response when the response hand and parity are congruent (*response_handright:parityeven* object) is 0.76:1, or 24% lower odds. This highlights smaller amount of evidence for an inverse MARC effect but misses out on being significant.
 
Line plot visualises the small amount of evidence for an interaction with an inverse MARC effect.

**Random effects**

Substantial variation between participants according to the standard deviation (SD = 0.67).

This finding is important, because a 2x2 ANOVA reveals a significant effect, however I do not believe it is the appropriate analysis. Also the logistc regression gives a more valid interpretation of the interaction. Rather than just saying "no interaction", it suggests that the odds of an accurate response do differ somewhat, but not a lot. This is something to think about. 

## Experimental condition - lawyer and cop present - SNARC effect error analysis - replication of slide 13

```{r, echo=FALSE}
"SNARC effect for errors"
workingdata$response_hand = factor(workingdata$response_hand, levels = c("left", "right"))
workingdata$magnitude = factor(workingdata$magnitude, levels = c("small", "large"))

ggplot(workingdata %>%
         dplyr::filter(condition == "explie") %>%
         drop_na() %>%
         dplyr::group_by(magnitude, response_hand) %>%
         dplyr::filter(accuracy == 0) %>%
         dplyr::summarise(errors = n()) %>%
         dplyr::ungroup(), aes(x = magnitude, color = response_hand, group = response_hand, y = errors)) +
         stat_summary(fun = mean, geom = "point") +
         stat_summary(fun = mean, geom = "line") +
  ylim(0, 250) +
  ylab("Number of errors") +
  xlab("Magnitude") +
  ggtitle("SNARC effect - error analysis")

SNARCeffect_model <- glmer(accuracy ~ response_hand * magnitude + (1 | participant),
             data = workingdata %>%
               drop_na() %>%
               dplyr::filter(condition == "explie") %>%
               drop_na(),
             family = binomial(link = "logit"))

summary(SNARCeffect_model)

exp(fixef(SNARCeffect_model))
exp(confint(SNARCeffect_model))
```

**Fixed effect**

The fixed effects coefficient for the interaction (*response_handright:magnitudelarge*) is 0.05 which corresponds to the log of odds ratio between congruent versus incongruent response hand/magnitude pairs.  We exponentiate it to reveal an odds ratio of 1.05 which means the odds of an accurate response are 1.05:1, or 5% higher when response hand and parity are congruent. This highlights the insigificant effect of the interaction.

The line plot visualises an interaction which might suggest there is an inverse SNARC effect, however the interaction is very small.

**Random effects**

Substantial variation between subjects according the standard deviations of the intercepts.
